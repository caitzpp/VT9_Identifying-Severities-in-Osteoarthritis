{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.evaluation_utils import print_ensemble_results, get_best_epoch\n",
    "from utils.load_utils import load_image\n",
    "from utils.label_eval_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7775b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = 'ss'\n",
    "#MOD_PREFIX = \"mod_2\"\n",
    "MOD_PREFIX = \"mod_st\"\n",
    "NEPOCH = 400\n",
    "MARGIN = 0.8\n",
    "\n",
    "#DATAPATH = config.CHENETAL_DATAPATH\n",
    "DATAPATH = config.SCHULTHESS_DATAPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22180f3f",
   "metadata": {},
   "source": [
    "## Visualize Results AS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db400150",
   "metadata": {},
   "source": [
    "### KL Score vs. Anom Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6344010",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = config.OUTPUT_PATH\n",
    "pseudolabels_path= os.path.join(SAVE_PATH, 'pseudolabels')\n",
    "\n",
    "try:\n",
    "    pseudolabel_names = [f\"{STAGE}_training_{MOD_PREFIX}_epoch_margin_{MARGIN}.csv\", f\"{STAGE}_training_{MOD_PREFIX}_on_test_set_margin_{MARGIN}.csv\"]\n",
    "    df = pd.read_csv(os.path.join(pseudolabels_path, pseudolabel_names[0]), index_col=False)\n",
    "    dftest = pd.read_csv(os.path.join(pseudolabels_path, pseudolabel_names[1]), index_col=False)\n",
    "except:\n",
    "    pseudolabel_names = [f\"{STAGE}_training_{MOD_PREFIX}_epoch_{NEPOCH}_margin_{MARGIN}.csv\", f\"{STAGE}_training_{MOD_PREFIX}_on_test_set_epoch_{NEPOCH}_margin_{MARGIN}.csv\"]\n",
    "    df = pd.read_csv(os.path.join(pseudolabels_path, pseudolabel_names[0]), index_col=False)\n",
    "    dftest = pd.read_csv(os.path.join(pseudolabels_path, pseudolabel_names[1]), index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbcf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048499e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_save_path = os.path.join(SAVE_PATH, 'graphs', STAGE)\n",
    "os.makedirs(graph_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_boxplot(df, dftest, \"anoms_count\", title=\"Anomality Count Distribution (Log)\", log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27927895",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'label'\n",
    "y = 'av'\n",
    "x_title = 'KL Score'\n",
    "y_title = 'Average AS'\n",
    "\n",
    "filename = f\"boxplot_{pseudolabel_names[0].split('.')[0]}_KLscore_AverageAS.png\"\n",
    "boxplot(df, x=x, y=y, x_title=x_title,y_title=y_title, title = \"Boxplot KL Score vs Average AS Train Data\", save_path=os.path.join(graph_save_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"boxplot_{pseudolabel_names[1].split('.')[0]}_KLscore_AverageAS.png\"\n",
    "boxplot(dftest, x=x, y=y, x_title=x_title,y_title=y_title, title = \"Boxplot KL Score vs Average AS Test Data\", save_path=os.path.join(graph_save_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Variability of AS over boxplots?\n",
    "# l = ['col_1001', 'col_71530', 'col_138647',\n",
    "#        'col_875688', 'col_985772', 'col_44', 'col_34', 'col_193', 'col_244959',\n",
    "#        'col_8765']\n",
    "\n",
    "# x = 'label'\n",
    "# x_title = 'KL Score'\n",
    "\n",
    "# #if I have a boxplot for every \"seed\" is there a better way of visualizing the variability that we see for the same samples across seeds?\n",
    "# # specifically also for the cases where we have inconsistent anomalie \"labels\"\n",
    "\n",
    "# for i in l:\n",
    "#     boxplot(df, x = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14183ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'sim'\n",
    "y = 'av'\n",
    "x_title = 'CLIP Sim Score'\n",
    "y_title = 'Average AS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1878d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [df, dftest]\n",
    "n = ['Train', 'Test']\n",
    "\n",
    "dataset = 'OAI' #ST\n",
    "\n",
    "for i in range(len(d)):\n",
    "    df1 = d[i]\n",
    "    scatter_plot(df1[df1['anoms_count']>0], x=x, y=y, x_title=x_title,y_title=y_title, label='label', title=f\"{dataset} - AS Score (>0) vs CLIP Sim Score (m=0.8) - {n[i]}\")\n",
    "    scatter_plot(df1[(df1['anoms_count']<=5) & (df1['anoms_count']>0)], x=x, y=y, x_title=x_title,y_title=y_title, label='label', title=f\"{dataset} - AS Score (<=5, >0) vs CLIP Sim Score (m=0.8) - {n[i]}\")\n",
    "    scatter_plot(df1, x=x, y=y, x_title=x_title,y_title=y_title, label='label', title=f\"{dataset} - AS Score vs CLIP Sim Score (m=0.8) - {n[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6af59",
   "metadata": {},
   "source": [
    "#### Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['label', 'anoms_count', 'sim', 'av']\n",
    "\n",
    "sns.pairplot(df[values], hue='label', palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4951c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dftest[values], hue='label', palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.PairGrid(df[values], hue='label')\n",
    "# g.map_lower(sns.boxplot) \n",
    "# g.map_diag(sns.histplot)  # Apply histogram for the diagonal\n",
    "# g.add_legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ceeac7",
   "metadata": {},
   "source": [
    "# Example X-Rays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892477c",
   "metadata": {},
   "source": [
    "## High CLIP Similarity Score for Different KL scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eee9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_l = []\n",
    "for i in range(len(pseudolabel_names)):\n",
    "    df1 = d[i]\n",
    "    ids = df1[df1['sim>95th']>0]\n",
    "    id_l.append(ids)\n",
    "\n",
    "    file_name = pseudolabel_names[i].rsplit('.', maxsplit=1)[0] + '_' + 'simscore_over_95th.csv'\n",
    "    save_path_ids = os.path.join(SAVE_PATH, 'eval', STAGE)\n",
    "    os.makedirs(save_path_ids, exist_ok=True)\n",
    "\n",
    "    ids.to_csv(os.path.join(save_path_ids, file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_save_path_train = os.path.join(SAVE_PATH, 'images', STAGE, 'train')\n",
    "img_save_path_test = os.path.join(SAVE_PATH, 'images', STAGE, 'test')\n",
    "\n",
    "\n",
    "for i in range(len(pseudolabel_names)):\n",
    "    pseudolabel_name = pseudolabel_names[i]\n",
    "    ids = id_l[i]\n",
    "    for i in range(0, 5):\n",
    "        l_img = []\n",
    "        temp_img_savepath_train = os.path.join(img_save_path_train, str(i))\n",
    "        temp_img_savepath_test = os.path.join(img_save_path_test, str(i))\n",
    "        os.makedirs(temp_img_savepath_train, exist_ok=True)\n",
    "        os.makedirs(temp_img_savepath_test, exist_ok=True)\n",
    "        for j in range(len(ids['id'])):\n",
    "            #print(int(ids['label'].iloc[j]))\n",
    "            if int(ids['label'].iloc[j]) == int(i):\n",
    "                l_img.append(ids['id'].iloc[j])\n",
    "            \n",
    "        for filename in l_img:\n",
    "            if \"on_test_set\" in pseudolabel_name:\n",
    "                img = load_image(os.path.join(DATAPATH, 'test', filename))\n",
    "                save_name = os.path.join(temp_img_savepath_test, f'{pseudolabel_name}_over95thpercentile{filename.split('/')[1]}')\n",
    "            else:\n",
    "                img = load_image(os.path.join(DATAPATH, 'train', filename))\n",
    "                save_name = os.path.join(temp_img_savepath_train, f'{pseudolabel_name}_over95thpercentile{filename.split('/')[1]}')\n",
    "            img.save(save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea7192",
   "metadata": {},
   "source": [
    "SAME FOR mod_st???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
