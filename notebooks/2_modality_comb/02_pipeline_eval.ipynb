{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from utils.data_exploration_utils import kruskal_wallis_analysis, barplots\n",
    "from utils.hdbscan_utils import plot_hdbscan, plot_hdbscan_highlight_kl, make_cluster_color_map\n",
    "from utils.plot_utils import plotly_hdbscan_highlight_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = 'ss'\n",
    "MOD_PREFIX = \"mod_smallimg3\"\n",
    "NEPOCH = 'latest'\n",
    "\n",
    "\n",
    "DATAPATH = config.OUTPUT_PATH\n",
    "base_dir = config.RAW_DATA_PATH\n",
    "img_path = config.SCHULTHESS_DATAPATH\n",
    "proc_dir = config.PROC_DATA_PATH\n",
    "\n",
    "folder = \"2025-10-17_hdbscan\"\n",
    "run = \"run17\"\n",
    "\n",
    "anomalyscore_metric = \"centre_mean\"\n",
    "cluster_col = \"cluster_label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f37031",
   "metadata": {},
   "source": [
    "## Load HDBSCAN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "folder_date = folder.split('_')[0]\n",
    "\n",
    "filepath = os.path.join(proc_dir, folder, \"pipeline\", run)\n",
    "save_path = os.path.join(filepath, \"img\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    hdbscan_df = pd.read_csv(os.path.join(filepath, f'pipeline_{run}_umap_hdbscan_scaled_allpoints_wKL.csv'))\n",
    "except:\n",
    "    hdbscan_df = pd.read_csv(os.path.join(filepath, f'pipeline_{run}_umap_hdbscan_scaled.csv'))\n",
    "    #.merge(kl_df, left_on = 'id', right_on='name', how='left', validate='one_to_one')\n",
    "    kl = pd.read_csv(os.path.join(proc_dir, \"2025-08-11_data_exploration\", \"inmodi_data_questionnaire_kl_woSC.csv\"))\n",
    "    hdbscan_df = hdbscan_df.merge(kl, left_on = 'id', right_on='name', how='left', validate='one_to_one')\n",
    "\n",
    "with open(os.path.join(filepath, f'pipeline_{run}_umap_hdbscan_scaled_model_info.json')) as f:\n",
    "    model_info= json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba21bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = model_info['files']['ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1105e1",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5482fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = os.path.join(filepath, \"X_umap_embeddings.npy\")\n",
    "X_umap = np.load(embeddings_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41932071",
   "metadata": {},
   "source": [
    "## Load MRI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri = pd.read_csv(os.path.join(base_dir, '2025-09-25_mrismall.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2ced7",
   "metadata": {},
   "source": [
    "## Load SS-FewSome Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = os.path.join(DATAPATH, 'outputs', 'dfs', STAGE)\n",
    "\n",
    "filepath2 =  []\n",
    "for file in os.listdir(outputs):\n",
    "    if MOD_PREFIX in file and str(NEPOCH) in file and '_all' in file:\n",
    "        filepath2.append(os.path.join(outputs, file))\n",
    "dfs = []\n",
    "for path in filepath2:\n",
    "    df = pd.read_csv(path)[['id', anomalyscore_metric]]  # only keep id + target col\n",
    "    dfs.append(df.rename(columns={anomalyscore_metric: os.path.basename(path)})) \n",
    "combined = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    combined = pd.merge(combined, df, on='id', how=\"inner\")  # 'inner' keeps only common IDs\n",
    "\n",
    "experiment_cols = [c for c in combined.columns if c != 'id']\n",
    "combined[\"mean\"] = combined[experiment_cols].mean(axis=1)\n",
    "combined[\"std\"] = combined[experiment_cols].std(axis=1)\n",
    "combined.to_csv(os.path.join(outputs, f\"{MOD_PREFIX}_{STAGE}_aggregated_scores.csv\"), index = False)\n",
    "combined['filepath'] = combined['id']\n",
    "combined['id'] = combined['id'].apply(lambda x: x.split('/')[-1].replace('.png', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mri))\n",
    "print(len(combined))\n",
    "print(len(hdbscan_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59520a04",
   "metadata": {},
   "source": [
    "## Create Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(combined), \"samples in combined dataframe\")\n",
    "print(len(hdbscan_df), \"samples in hdbscan dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f42f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = combined.merge(hdbscan_df, on='id', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfc), \"samples in combined dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc['mean'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9258e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc2 = mri.merge(dfc, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c20f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hdbscan_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea294e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfc2[dfc2['mri_cart_yn'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c5a48b",
   "metadata": {},
   "source": [
    "# Anomaly Score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22596782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb2 = combined.iloc[:, :-3]\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(combined['mean'], bins=20)\n",
    "plt.title('Distribution of Mean Values')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec30d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x='cluster_label', y='mean', data=dfc)\n",
    "plt.title('Boxplot of Mean Anomaly Scores by Cluster Label')\n",
    "plt.xlabel('Cluster Label') \n",
    "plt.ylabel('Mean Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min. Anomaly Score: {combined['mean'].min():.3f}\")\n",
    "print(f\"Max. Anomaly Score: {combined['mean'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec36860",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in df['cluster_label'].unique():\n",
    "    cluster_data = dfc[dfc['cluster_label'] == cluster]['mean']\n",
    "    print(f\"Cluster {cluster}: n={len(cluster_data)}, mean={cluster_data.mean():.3f}, std={cluster_data.std():.3f}, min={cluster_data.min():.3f}, max={cluster_data.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7d025",
   "metadata": {},
   "source": [
    "# Test Grouping of AS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Groups of Anomaly Scores\n",
    "def assign_as_group(mean_score):\n",
    "    if mean_score < 0.3:\n",
    "        return 'Low'\n",
    "    elif 0.3 <= mean_score < 0.6:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_columns = [ 'mri_operator',\n",
    " 'mri_side',\n",
    " 'mri_bml_yn',\n",
    " 'mri_cart_yn',\n",
    " 'mri_osteo_yn',\n",
    " 'mri_syn_yn',\n",
    " 'mri_mnsc_yn',\n",
    " 'mri_lig_yn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32aaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc2['AS_Group'] = dfc2['mean'].apply(assign_as_group)\n",
    "\n",
    "# display(dfc2['AS_Group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc2_nonan = dfc2.dropna(subset=['AS_Group', 'cluster_label'])\n",
    "# pd.crosstab(dfc2_nonan['AS_Group'], dfc2_nonan['cluster_label'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df147a2",
   "metadata": {},
   "source": [
    "# Some Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16374d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_label'].value_counts().reset_index().sort_values('cluster_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df['cluster_label'].value_counts().reset_index().sort_values(by='cluster_label')\n",
    "\n",
    "plt.bar(values['cluster_label'], values['count'], color = 'skyblue')\n",
    "plt.xlabel('Cluster Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a990d",
   "metadata": {},
   "source": [
    "### Cluster Label vs KL-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4486f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot\n",
    "color_map = make_cluster_color_map(df['KL-Score'].unique())\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.catplot(data = df, x='cluster_label', y='probability', hue='KL-Score', palette=color_map, jitter = 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d10baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kls = sorted(df['cluster_label'].unique())\n",
    "kls = [kl for kl in kls if kl != -1]  # exclude noise\n",
    "\n",
    "ncols = 2\n",
    "nrows = math.ceil(len(kls)/ncols)\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(20, 4*nrows), sharey=True)\n",
    "ax = np.ravel(ax)  # flatten to 1D\n",
    "\n",
    "for idx, kl in enumerate(kls):\n",
    "    sns.boxplot(\n",
    "        data=df[df['cluster_label'] == kl],\n",
    "        x='KL-Score', y='probability',\n",
    "        ax=ax[idx], color=color_map[kl]\n",
    "    )\n",
    "    ax[idx].set_title(f\"cluster_label = {kl}\")\n",
    "\n",
    "# hide any unused axes\n",
    "for j in range(len(kls), len(ax)):\n",
    "    ax[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_path, f'{folder}_{run}_probability_cluster_klscore_v2_rawq.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb46e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='cluster_label', hue='KL-Score', multiple='dodge', palette=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f903c5a",
   "metadata": {},
   "source": [
    "## Cluster Label vs MRI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_cols = ['mri_cart_yn', 'mri_osteo_yn', 'mri_bml_yn']\n",
    "\n",
    "for mri_col in mri_cols:\n",
    "    kls = sorted(dfc2[mri_col].unique())\n",
    "\n",
    "    ncols = 2\n",
    "    nrows = math.ceil(len(kls)/ncols)\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(20, 4*nrows), sharey=True)\n",
    "    ax = np.ravel(ax)  # flatten to 1D\n",
    "\n",
    "    for idx, kl in enumerate(kls):\n",
    "        sns.boxplot(\n",
    "            data=dfc2[dfc2[mri_col] == kl],\n",
    "            x='cluster_label', y='probability',\n",
    "            ax=ax[idx], color=color_map[kl]\n",
    "        )\n",
    "        ax[idx].set_title(f\"{mri_col} = {kl}\")\n",
    "\n",
    "    # hide any unused axes\n",
    "    for j in range(len(kls), len(ax)):\n",
    "        ax[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'{folder}_{run}_probability_cluster_{mri_col}_rawq.png'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=dfc2, x='cluster_label', hue=mri_col, multiple='dodge', palette=color_map)\n",
    "    plt.savefig(os.path.join(save_path, f'{folder}_{run}_histogram_cluster_{mri_col}_rawq.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9680954",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "def kruskal_wallis(df, feature, cluster_col = 'cluster_label'):\n",
    "    groups = [df.loc[df[cluster_col]==cluster, feature] for cluster in df[cluster_col].unique()]\n",
    "    stat, p = kruskal(*groups)\n",
    "    return stat, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35fbb91",
   "metadata": {},
   "source": [
    "## Correlation with KL-Score and Pain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292cdc1",
   "metadata": {},
   "source": [
    "### Kruscal Wallis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1578793",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corr = [  \n",
    " 'pain', 'age',\n",
    "       'ce_bmi', 'ce_fm'\n",
    "       ] \n",
    "\n",
    "for feature in columns_corr:\n",
    "    for c in dfc2[\"cluster_label\"].unique():\n",
    "        print(f\"NaN values: {dfc2[feature].isna().sum()}\")\n",
    "        vals = dfc2.loc[dfc2[\"cluster_label\"]==c, feature].dropna()\n",
    "        print(f\"For Feature {feature}\")\n",
    "        print(f\"Cluster {c}: n={len(vals)}, unique={vals.nunique()}, min={vals.min()}, max={vals.max()}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for feature in columns_corr:\n",
    "       dfc2_wonan = dfc2.dropna(subset=[feature])\n",
    "       stat, p = kruskal_wallis(dfc2_wonan, feature, cluster_col = 'cluster_label')\n",
    "       # print(f\"Kruskal-Wallis test for {feature}: H-statistic = {stat:.3f}, p-value = {p:.3e}\")\n",
    "       results.append({'feature': feature, 'H-statistic': stat, 'p-value': p})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# results_df = results_df.sort_values('p-value')\n",
    "\n",
    "display(results_df.sort_values('p-value').head())\n",
    "results_df.to_csv(os.path.join(filepath, f\"kruskal_wallis_results_{run}.csv\"), index=False)\n",
    "\n",
    "results_df[results_df['p-value'] >= 0.05]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data = results_df, x='feature', y='H-statistic')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(columns_corr)):\n",
    "    dfc_wonan = dfc2.copy()\n",
    "    dfc_wonan = dfc_wonan.dropna(subset=[columns_corr[i]])\n",
    "    print(f\"Kruskal-Wallis analysis for feature: {columns_corr[i]}\")\n",
    "    kruskal_wallis_analysis(dfc_wonan, columns_corr[i], cluster_col='cluster_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_col = ['mri_cart_yn', 'mri_osteo_yn', 'mri_bml_yn']\n",
    "\n",
    "results = []\n",
    "for feature in mri_col:\n",
    "       dfc2_wonan = dfc2.dropna(subset=[feature, 'cluster_label'])\n",
    "       stat, p = kruskal_wallis(dfc2_wonan, feature, cluster_col = 'cluster_label')\n",
    "       # print(f\"Kruskal-Wallis test for {feature}: H-statistic = {stat:.3f}, p-value = {p:.3e}\")\n",
    "       results.append({'feature': feature, 'H-statistic': stat, 'p-value': p})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# results_df = results_df.sort_values('p-value')\n",
    "\n",
    "display(results_df.sort_values('p-value').head())\n",
    "results_df.to_csv(os.path.join(filepath, f\"kruskal_wallis_results_{run}.csv\"), index=False)\n",
    "\n",
    "results_df[results_df['p-value'] >= 0.05]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data = results_df, x='feature', y='H-statistic')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "for col in mri_col:\n",
    "    dfc_wonan = dfc2.copy()\n",
    "    dfc_wonan = dfc_wonan.dropna(subset=[col, 'cluster_label'])\n",
    "    print(len(dfc_wonan), \"samples after dropping NaNs for\", col)\n",
    "    kruskal_wallis_analysis(dfc_wonan, col, cluster_col='cluster_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a463a",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corr =  ['mri_cart_yn', 'mri_osteo_yn', 'mri_bml_yn'] \n",
    "barplots(dfc2, y_list=columns_corr, x='cluster_label', hue=None, figsize = (6, 6), savepath=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d374a7d",
   "metadata": {},
   "source": [
    "# Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65826e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(df, cluster_col, feature_col):\n",
    "    clusters = df[cluster_col].unique()\n",
    "    clusters.sort()\n",
    "\n",
    "    results = pd.DataFrame({cluster_col: clusters})\n",
    "\n",
    "    for feature in feature_col:\n",
    "        majority_vote = df.groupby(cluster_col)[feature].agg(lambda x: list(x.mode()))\n",
    "        majority_vote = pd.DataFrame(majority_vote).reset_index()\n",
    "        majority_vote = majority_vote.rename(columns={feature: f'MV_{feature}'})\n",
    "        results = results.merge(majority_vote, on = cluster_col, how = 'left')\n",
    "\n",
    "    return results.dropna(axis=0, how='all')\n",
    "\n",
    "def handle_modes(x, id_):\n",
    "    if len(x) == 1:\n",
    "        try:\n",
    "            return float(x[0])\n",
    "        except Exception as e:\n",
    "            print(f\"Conversion error for id={id_}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Tie detected for id={id_}: {x}\")\n",
    "        return None  \n",
    "    \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
    "def get_metrics(df, feature):\n",
    "    y_true = df[feature]\n",
    "    y_pred = df[f'MV_{feature}']\n",
    "\n",
    "    print(f'For Feature {feature}:')\n",
    "    precision=precision_score(y_true, y_pred, average='macro')\n",
    "    print(\"Precision:\", precision)\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    print(\"Recall:\", recall)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(\"F1 Score:\", f1)\n",
    "    # if len(np.unique(y_true))>2:\n",
    "    #     print(\"ROC_AUC:\", roc_auc_score(y_true, y_pred, multi_class='ovo'))\n",
    "    # else:\n",
    "    #     print(\"ROC_AUC:\", roc_auc_score(y_true, y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\")\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(os.path.join(filepath, f'{feature}_confusionmatrix.png'))\n",
    "    plt.show()\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def get_metrics_percluster(df, feature, cluster_col = 'cluster_label', normalized=False):\n",
    "    print(f'For Feature {feature}:')\n",
    "    clusters = np.unique(df[cluster_col])\n",
    "\n",
    "    for c in clusters:\n",
    "        mask = df[cluster_col] ==c\n",
    "\n",
    "        if mask.sum()<2:\n",
    "            print(f'Skipping cluster {c}: only {mask.sum()} samples')\n",
    "            continue\n",
    "        y_pred = df.loc[mask, f'MV_{feature}']\n",
    "        y_true = df.loc[mask, feature]\n",
    "\n",
    "        cm = confusion_matrix(\n",
    "                y_true,\n",
    "                y_pred,\n",
    "                normalize='true' if normalized else None\n",
    "            )\n",
    "        \n",
    "        labels = sorted(np.unique(y_true.tolist() + y_pred.tolist()))\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt='.2f' if normalized else 'd',\n",
    "            cmap='YlGnBu',\n",
    "            cbar=False,\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels\n",
    "        )\n",
    "        plt.title(f'Confusion Matrix â€“ Cluster {c} ({mask.sum()} samples)')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d705b1f",
   "metadata": {},
   "source": [
    "## Plot Distribution per cluster first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46757e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['mri_bml_yn', 'mri_cart_yn', 'mri_osteo_yn', 'mri_syn_yn', 'mri_mnsc_yn', 'mri_lig_yn']\n",
    "\n",
    "for feature in feature_col:\n",
    "    clusters = dfc2['cluster_label'].unique()\n",
    "    clusters.sort()\n",
    "\n",
    "    counts = dfc2.groupby(['cluster_label', feature]).size().unstack(fill_value=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    counts.plot(kind='bar', stacked=False)\n",
    "    plt.title(f'Distribution of {feature} across clusters')\n",
    "    plt.xlabel('Cluster Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230cc15",
   "metadata": {},
   "source": [
    "## Majority Vote official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f924301",
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_vote = majority_vote(dfc2, 'cluster_label', feature_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79140371",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_col:\n",
    "    col_name = f'MV_{feature}'\n",
    "    maj_vote[col_name] = [\n",
    "        handle_modes(row[col_name], row['cluster_label'])\n",
    "        for _, row in maj_vote.iterrows()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(maj_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96537474",
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_vote.to_csv(os.path.join(filepath, 'maj_vote_eval.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c662a",
   "metadata": {},
   "source": [
    "## Calculate Precision, Recall, F1-Score etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc3 = dfc2.merge(maj_vote, how = 'left', on= 'cluster_label')\n",
    "dfc3 = dfc3.dropna(subset=['cluster_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    feature_col.remove('KL-Score')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97423b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame()\n",
    "\n",
    "for feature in feature_col:\n",
    "    precision, recall, f1 = get_metrics(dfc3, feature)\n",
    "    results = {'feature': feature,\n",
    "               'precision': precision,\n",
    "               'recall': recall,\n",
    "               'f1_score': f1}\n",
    "    results = pd.DataFrame([results])\n",
    "    metrics = pd.concat([metrics, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_col:\n",
    "    get_metrics_percluster(dfc3, feature, normalized=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
