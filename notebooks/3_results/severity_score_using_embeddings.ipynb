{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "import config\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = 'ss'\n",
    "MOD_PREFIX = \"mod_smallimg3\"\n",
    "NEPOCH = 'latest'\n",
    "\n",
    "\n",
    "DATAPATH = config.OUTPUT_PATH\n",
    "base_dir = config.RAW_DATA_PATH\n",
    "img_path = config.SCHULTHESS_DATAPATH\n",
    "proc_dir = config.PROC_DATA_PATH\n",
    "\n",
    "# #for rawq:\n",
    "feature = 'rawq'\n",
    "methods = 'comb_modalities'\n",
    "folder = \"2026-01-17_hdbscan\"\n",
    "run = \"run28\"  \n",
    "\n",
    "# folder = \"2025-11-19_hdbscan\"\n",
    "# methods = 'pipeline'\n",
    "# run = \"run10\"  \n",
    "\n",
    "anomalyscore_metric = \"centre_mean\"\n",
    "cluster_col = \"cluster_label\"\n",
    "\n",
    "folder_date = folder.split('_')[0]\n",
    "\n",
    "if feature == 'rawq':\n",
    "    filepath = os.path.join(proc_dir, folder, methods, run)\n",
    "#     hdbscan_df = pd.read_csv(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_scaled.csv'))\n",
    "    hdbscan_df = pd.read_csv(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_scaled.csv'))\n",
    "    if methods == 'comb_modalities':\n",
    "        hdbscan_df_test = pd.read_csv(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_scaled_test_results.csv'))\n",
    "elif feature == 'img_features' or feature == 'img_raw':\n",
    "        filepath = os.path.join(proc_dir, \"radiographic_features\", folder, run)\n",
    "        hdbscan_df = pd.read_csv(os.path.join(filepath, f'{folder}_{run}_umap_hdbscan_scaled.csv'))\n",
    "elif feature == 'agg':\n",
    "      filepath = os.path.join(proc_dir, folder, run)\n",
    "      hdbscan_df = pd.read_csv(os.path.join(filepath, f'{folder}_{run}_umap_hdbscan_scaled.csv'))\n",
    "        \n",
    "kl = pd.read_csv(os.path.join(base_dir,  \"brul_knee_annotations.csv\"))\n",
    "kl2 = pd.read_csv(os.path.join(base_dir, \"rosand1_knee_annotations.csv\"))\n",
    "mri = pd.read_csv(os.path.join(base_dir, '2025-09-25_mrismall.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = os.path.join(DATAPATH, 'outputs', 'dfs', STAGE)\n",
    "\n",
    "filepath2 =  []\n",
    "for file in os.listdir(outputs):\n",
    "    if MOD_PREFIX in file and str(NEPOCH) in file and '_all' in file:\n",
    "        filepath2.append(os.path.join(outputs, file))\n",
    "dfs = []\n",
    "for path in filepath2:\n",
    "    df = pd.read_csv(path)[['id', anomalyscore_metric]]  # only keep id + target col\n",
    "    dfs.append(df.rename(columns={anomalyscore_metric: os.path.basename(path)})) \n",
    "combined = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    combined = pd.merge(combined, df, on='id', how=\"inner\")  # 'inner' keeps only common IDs\n",
    "\n",
    "experiment_cols = [c for c in combined.columns if c != 'id']\n",
    "combined[\"mean\"] = combined[experiment_cols].mean(axis=1)\n",
    "combined[\"std\"] = combined[experiment_cols].std(axis=1)\n",
    "combined.to_csv(os.path.join(outputs, f\"{MOD_PREFIX}_{STAGE}_aggregated_scores.csv\"), index = False)\n",
    "combined['filepath'] = combined['id']\n",
    "combined['id'] = combined['id'].apply(lambda x: x.split('/')[-1].replace('.png', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ac165",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_df = \"2025-09-11_data_exploration\"\n",
    "df_filename = \"inmodi_data_questionnaire_kl_woSC.csv\"\n",
    "qdf = pd.read_csv(os.path.join(proc_dir, folder_df, df_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'KL-Score' not in hdbscan_df.columns:\n",
    "    hdbscan_df = hdbscan_df.merge(qdf[['pain', 'age', 'ce_height',\n",
    "       'ce_weight', 'ce_bmi', 'ce_fm', 'gender', 'OKS_score', 'UCLA_score',\n",
    "       'FJS_score', 'KOOS_pain', 'KOOS_symptoms', 'KOOS_sport', 'KOOS_adl',\n",
    "       'KOOS_qol', 'name', 'KL-Score', 'oks_q1', 'oks_q2', 'oks_q3', 'oks_q4',\n",
    "       'oks_q5', 'oks_q6', 'oks_q7', 'oks_q8', 'oks_q9', 'oks_q10', 'oks_q11',\n",
    "       'oks_q12', 'koos_s1', 'koos_s2', 'koos_s3', 'koos_s4', 'koos_s5',\n",
    "       'koos_s6', 'koos_s7', 'koos_p1', 'koos_p2', 'koos_p3', 'koos_p4',\n",
    "       'koos_p5', 'koos_p6', 'koos_p7', 'koos_p8', 'koos_p9', 'koos_a1',\n",
    "       'koos_a2', 'koos_a3', 'koos_a4', 'koos_a5', 'koos_a6', 'koos_a7',\n",
    "       'koos_a8', 'koos_a9', 'koos_a10', 'koos_a11', 'koos_a12', 'koos_a13',\n",
    "       'koos_a14', 'koos_a15', 'koos_a16', 'koos_a17', 'koos_sp1', 'koos_sp2',\n",
    "       'koos_sp3', 'koos_sp4', 'koos_sp5', 'koos_q1', 'koos_q2', 'koos_q3',\n",
    "       'koos_q4']], left_on='id', right_on='name', how='left')\n",
    "    hdbscan_df = hdbscan_df.merge(combined, on='id', how='left')\n",
    "\n",
    "    try:\n",
    "        hdbscan_df_test = hdbscan_df_test.merge(qdf[['pain', 'age', 'ce_height',\n",
    "       'ce_weight', 'ce_bmi', 'ce_fm', 'gender', 'OKS_score', 'UCLA_score',\n",
    "       'FJS_score', 'KOOS_pain', 'KOOS_symptoms', 'KOOS_sport', 'KOOS_adl',\n",
    "       'KOOS_qol', 'name', 'KL-Score', 'oks_q1', 'oks_q2', 'oks_q3', 'oks_q4',\n",
    "       'oks_q5', 'oks_q6', 'oks_q7', 'oks_q8', 'oks_q9', 'oks_q10', 'oks_q11',\n",
    "       'oks_q12', 'koos_s1', 'koos_s2', 'koos_s3', 'koos_s4', 'koos_s5',\n",
    "       'koos_s6', 'koos_s7', 'koos_p1', 'koos_p2', 'koos_p3', 'koos_p4',\n",
    "       'koos_p5', 'koos_p6', 'koos_p7', 'koos_p8', 'koos_p9', 'koos_a1',\n",
    "       'koos_a2', 'koos_a3', 'koos_a4', 'koos_a5', 'koos_a6', 'koos_a7',\n",
    "       'koos_a8', 'koos_a9', 'koos_a10', 'koos_a11', 'koos_a12', 'koos_a13',\n",
    "       'koos_a14', 'koos_a15', 'koos_a16', 'koos_a17', 'koos_sp1', 'koos_sp2',\n",
    "       'koos_sp3', 'koos_sp4', 'koos_sp5', 'koos_q1', 'koos_q2', 'koos_q3',\n",
    "       'koos_q4']], left_on='id', right_on='name', how='left')\n",
    "        hdbscan_df_test = hdbscan_df_test.merge(combined, on='id', how='left')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56128c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df_test['cluster_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df['cluster_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9792b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = pd.read_csv(os.path.join(base_dir, 'questionnaires_raw.csv')) #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25796447",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    hdbscan_df.drop(columns=['name_y', 'KL-Score_y'], inplace=True)\n",
    "    hdbscan_df.rename(columns={'name_x': 'name', 'KL-Score_x': 'KL-Score'}, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae548a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hdbscan_df))\n",
    "print(len(hdbscan_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hdbscan_df))\n",
    "print(len(hdbscan_df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14db69",
   "metadata": {},
   "source": [
    "# Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_scaled_model_info.json')) as f:\n",
    "    model_info= json.load(f)\n",
    "if methods == 'comb_modalities':\n",
    "    umap_info = model_info['params']['umap']\n",
    "    nneigh = umap_info['n_neighbors']\n",
    "    min_dist = umap_info['min_dist']\n",
    "    metric = umap_info['metric']\n",
    "\n",
    "    umap_folder = f'nneigh{nneigh}_mindist{min_dist}_metric{metric}'\n",
    "    umap_path = os.path.join(proc_dir, '2026-01-16_umap_scaler_values', 'comb_modalities', umap_folder)\n",
    "\n",
    "    with open(os.path.join(umap_path, 'smote_oversampled_data_artifacts.json')) as f:\n",
    "        umap_artifacts = json.load(f)\n",
    "\n",
    "    ids = umap_artifacts['ids']\n",
    "\n",
    "    embeddings_path = os.path.join(umap_path, 'X_umap_embeddings.npy')\n",
    "    embeddings = np.load(embeddings_path)\n",
    "\n",
    "    embeddings_path_test = os.path.join(filepath, 'X_test_umap_embeddings.npy')\n",
    "    embeddings_test = np.load(embeddings_path_test)\n",
    "\n",
    "    embeddings_smote_path = os.path.join(umap_path, 'X_umap_samp_embeddings.npy')\n",
    "\n",
    "    try:\n",
    "        smote_path = os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_generated_samples_predicted.csv')\n",
    "        smote_df = pd.read_csv(smote_path)\n",
    "        #test if cluster_label in smote_df\n",
    "        if 'cluster_label' not in smote_df.columns:\n",
    "            raise FileNotFoundError\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    smote_path = os.path.join(umap_path, 'SMOTE_generated_samples.csv')\n",
    "    smote_df = pd.read_csv(smote_path)\n",
    "    smote_embeddings = np.load(embeddings_smote_path)\n",
    "\n",
    "    clusterer = joblib.load(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_scaled_clusterer.pkl'))\n",
    "    smote_df['cluster_label'] = clusterer.labels_\n",
    "\n",
    "else:\n",
    "    embeddings_path = os.path.join(filepath, \"X_umap_embeddings.npy\")\n",
    "    embeddings = np.load(embeddings_path)\n",
    "\n",
    "    embeddings_smote_path = os.path.join(filepath, 'X_umap_samp_embeddings.npy')\n",
    "    smote_embeddings = np.load(embeddings_smote_path)\n",
    "\n",
    "    smote_path = os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_generated_samples_predicted.csv')\n",
    "\n",
    "    smote_df = pd.read_csv(smote_path)\n",
    "\n",
    "    ids = model_info['files']['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hdbscan_df))\n",
    "print(len(embeddings))\n",
    "\n",
    "print(len(smote_df))\n",
    "print(len(smote_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hdbscan_df_test))\n",
    "print(len(embeddings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18754d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdbscan_df_test = hdbscan_df_test[hdbscan_df_test['cluster_label']!=-1]\n",
    "ids_test = hdbscan_df_test['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hdbscan_df))\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df_wo = hdbscan_df[hdbscan_df['cluster_label']!=-1]\n",
    "hdbscan_df_test_wo = hdbscan_df_test[hdbscan_df_test['cluster_label']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = model_info['files']['ids']\n",
    "\n",
    "if len(embeddings)>len(hdbscan_df_wo):\n",
    "    #create mapping\n",
    "\n",
    "    embeddings_won = embeddings[ids.index(hdbscan_df_wo['id'].iloc[0]): ids.index(hdbscan_df_wo['id'].iloc[-1])+1]\n",
    "    embeddings_won = embeddings_won[[ids.index(i) for i in hdbscan_df_wo['id']]]\n",
    "    ids_wo = [i for i in ids if i in hdbscan_df_wo['id'].tolist()]\n",
    "\n",
    "if len(embeddings_test)>len(hdbscan_df_test_wo):\n",
    "    embeddings_test_won = embeddings_test[ids_test.index(hdbscan_df_test_wo['id'].iloc[0]): ids_test.index(hdbscan_df_test_wo['id'].iloc[-1])+1]\n",
    "    embeddings_test_won = embeddings_test_won[[ids_test.index(i) for i in hdbscan_df_test_wo['id']]]\n",
    "    ids_test_wo = [i for i in ids_test if i in hdbscan_df_test_wo['id'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82203a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hdbscan_df_wo))\n",
    "print(len(embeddings_won))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ids_test))\n",
    "print(len(embeddings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf315df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = hdbscan_df['cluster_label'].unique().tolist()\n",
    "clusters.sort()\n",
    "\n",
    "healthy_cluster = 0\n",
    "healthy_centroid = embeddings[hdbscan_df['cluster_label'] == healthy_cluster].mean(axis=0)\n",
    "healthy_spread = np.mean(np.linalg.norm(embeddings[hdbscan_df['cluster_label'] == healthy_cluster]-healthy_centroid, axis=1))\n",
    "\n",
    "cluster_centroids = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_embeddings = embeddings[hdbscan_df['cluster_label'] == cluster]\n",
    "    cluster_centroid = cluster_embeddings.mean(axis=0)\n",
    "    spread = np.mean(np.linalg.norm(cluster_embeddings-cluster_centroid, axis=1))\n",
    "    cluster_centroids[cluster] = {\n",
    "        'centroid': cluster_centroid,\n",
    "        'distance': np.linalg.norm(cluster_centroid-healthy_centroid),\n",
    "        'spread': spread,\n",
    "        'norm_distance': np.linalg.norm(cluster_centroid - healthy_centroid)/(healthy_spread+spread)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_mask = hdbscan_df['cluster_label'] == healthy_cluster\n",
    "healthy_embeddings = embeddings[healthy_mask]\n",
    "healthy_centroid = healthy_embeddings.mean(axis=0)\n",
    "\n",
    "healthy_spread = np.mean(\n",
    "    np.linalg.norm(\n",
    "        healthy_embeddings - healthy_centroid,\n",
    "        axis=1\n",
    "    )\n",
    ")\n",
    "dist_to_healthy = cdist(embeddings, healthy_embeddings)\n",
    "\n",
    "point_severity = dist_to_healthy.min(axis=1)\n",
    "\n",
    "cluster_centroids = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_mask = hdbscan_df['cluster_label'] == cluster\n",
    "    cluster_embeddings = embeddings[cluster_mask]\n",
    "\n",
    "    # centroid (for reference / plotting)\n",
    "    cluster_centroid = cluster_embeddings.mean(axis=0)\n",
    "\n",
    "    # spread = mean distance to centroid\n",
    "    spread = np.mean(\n",
    "        np.linalg.norm(cluster_embeddings - cluster_centroid, axis=1)\n",
    "    )\n",
    "\n",
    "    # NEW: cluster distance = mean nearest-healthy distance\n",
    "    cluster_distance = point_severity[cluster_mask].mean()\n",
    "    print(f\"Cluster {cluster}: distance to healthy = {cluster_distance}, spread = {spread}\")\n",
    "\n",
    "    # normalized distance\n",
    "    denom = healthy_spread + spread\n",
    "    norm_distance = cluster_distance / denom if denom > 0 else np.nan\n",
    "\n",
    "    cluster_centroids[cluster] = {\n",
    "        'centroid': cluster_centroid,\n",
    "        'distance': cluster_distance,\n",
    "        'spread': spread,\n",
    "        'norm_distance': norm_distance\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ef39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_distance(row, embeddings):\n",
    "    c = row['cluster_label']\n",
    "    point = embeddings[row.name]\n",
    "\n",
    "    raw_distance = np.linalg.norm(point - healthy_centroid)\n",
    "    norm = cluster_centroids[c]['spread'] + cluster_centroids[healthy_cluster]['spread']\n",
    "\n",
    "    return raw_distance / norm if norm >0 else raw_distance #np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb9d8e",
   "metadata": {},
   "source": [
    "## Order using SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_mask = smote_df['cluster_label'] == healthy_cluster\n",
    "healthy_embeddings = smote_embeddings[healthy_mask]\n",
    "healthy_centroid = healthy_embeddings.mean(axis=0)\n",
    "\n",
    "healthy_spread = np.mean(\n",
    "    np.linalg.norm(\n",
    "        healthy_embeddings - healthy_centroid,\n",
    "        axis=1\n",
    "    )\n",
    ")\n",
    "dist_to_healthy = cdist(smote_embeddings, healthy_embeddings)\n",
    "\n",
    "point_severity = dist_to_healthy.min(axis=1)\n",
    "\n",
    "cluster_centroids = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_mask = smote_df['cluster_label'] == cluster\n",
    "    cluster_embeddings = smote_embeddings[cluster_mask]\n",
    "\n",
    "    # centroid (for reference / plotting)\n",
    "    cluster_centroid = cluster_embeddings.mean(axis=0)\n",
    "\n",
    "    # spread = mean distance to centroid\n",
    "    spread = np.mean(\n",
    "        np.linalg.norm(cluster_embeddings - cluster_centroid, axis=1)\n",
    "    )\n",
    "\n",
    "    # NEW: cluster distance = mean nearest-healthy distance\n",
    "    cluster_distance = point_severity[cluster_mask].mean()\n",
    "    print(f\"Cluster {cluster}: distance to healthy = {cluster_distance}, spread = {spread}\")\n",
    "\n",
    "    # normalized distance\n",
    "    denom = healthy_spread + spread\n",
    "    norm_distance = cluster_distance / denom if denom > 0 else np.nan\n",
    "\n",
    "    cluster_centroids[cluster] = {\n",
    "        'centroid': cluster_centroid,\n",
    "        'distance': cluster_distance,\n",
    "        'spread': spread,\n",
    "        'norm_distance': norm_distance\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in cluster_centroids:\n",
    "    print(f\"Cluster {cluster}: norm. distance is {cluster_centroids[cluster]['norm_distance']}, with spread {cluster_centroids[cluster]['spread']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d37bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderd = sorted(cluster_centroids.items(), key=lambda x: x[1]['norm_distance'])\n",
    "order_wonoised = [item for item in orderd if item[0] != -1]\n",
    "order = {cluster: rank for rank, (cluster, _) in enumerate(order_wonoised)}\n",
    "cluster_mapping = {cluster: rank for rank, (cluster, _) in enumerate(order_wonoised)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93309d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_distance(row, embeddings):\n",
    "    c = row['cluster_label']\n",
    "\n",
    "    if pd.isna(c):\n",
    "        return np.nan   # or raw_distance, depending on your intent\n",
    "\n",
    "    point = embeddings[row.name]\n",
    "    raw_distance = np.linalg.norm(point - healthy_centroid)\n",
    "\n",
    "    norm = (\n",
    "        cluster_centroids[c]['spread']\n",
    "        + cluster_centroids[healthy_cluster]['spread']\n",
    "    )\n",
    "\n",
    "    return raw_distance / norm if norm > 0 else np.nan\n",
    "\n",
    "# smote_df['old_label'] = smote_df['cluster_label']\n",
    "# smote_df['cluster_label'] = smote_df['cluster_label'].map(cluster_mapping)\n",
    "smote_df['severity_score'] = np.linalg.norm(smote_embeddings - healthy_centroid, axis=1)\n",
    "smote_df['severity_score_norm'] = smote_df.apply(normalized_distance, axis = 1, embeddings= smote_embeddings)\n",
    "# smote_df.to_csv(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_smote_clusters.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b42851",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_df.groupby(\"cluster_label\")[\"severity_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_df.groupby(\"cluster_label\")[\"severity_score_norm\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcd7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_df['old_label'] = smote_df['cluster_label']\n",
    "smote_df['cluster_label'] = smote_df['cluster_label'].map(cluster_mapping)\n",
    "smote_df.to_csv(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_smote_clusters.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f139ab",
   "metadata": {},
   "source": [
    "### Get updated original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df['severity_score'] = np.linalg.norm(embeddings - healthy_centroid, axis=1)\n",
    "hdbscan_df['severity_score_norm'] = hdbscan_df.apply(normalized_distance, axis = 1, embeddings= embeddings)\n",
    "hdbscan_df['severity_score_norm_cluster'] = hdbscan_df['cluster_label'].apply(lambda x: cluster_centroids[x]['norm_distance'])\n",
    "hdbscan_df['severity_score_manhatten'] = np.abs(np.linalg.norm(embeddings - healthy_centroid, ord=1, axis=1))\n",
    "hdbscan_df['severity_score_chebyshev'] = np.abs(np.linalg.norm(embeddings - healthy_centroid, ord=np.inf, axis=1))\n",
    "try:\n",
    "    hdbscan_df_test['severity_score'] = np.linalg.norm(embeddings_test - healthy_centroid, axis=1)\n",
    "    hdbscan_df_test['severity_score_norm'] = hdbscan_df_test.apply(normalized_distance, axis = 1, embeddings= embeddings_test)\n",
    "    hdbscan_df_test['severity_score_norm_cluster'] = hdbscan_df_test['cluster_label'].apply(lambda x: cluster_centroids[x]['norm_distance'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859638cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df_test['severity_score'] = np.linalg.norm(embeddings_test - healthy_centroid, axis=1)\n",
    "hdbscan_df_test['severity_score_norm'] = hdbscan_df_test.apply(normalized_distance, axis = 1, embeddings= embeddings_test)\n",
    "hdbscan_df_test['severity_score_norm_cluster'] = hdbscan_df_test['cluster_label'].apply(lambda x: cluster_centroids[x]['norm_distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ee1a7",
   "metadata": {},
   "source": [
    "# Severity Score Behaviour for each cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df_wo['old_cluster'] = hdbscan_df_wo['cluster_label']\n",
    "hdbscan_df_wo['cluster_label'] = hdbscan_df_wo['cluster_label'].map(cluster_mapping)\n",
    "#replace cluster_label Nan with -1\n",
    "hdbscan_df_wo['cluster_label'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_df_test_wo['old_cluster'] = hdbscan_df_test_wo['cluster_label']\n",
    "hdbscan_df_test_wo['cluster_label'] = hdbscan_df_test_wo['cluster_label'].map(cluster_mapping)\n",
    "#replace cluster_label Nan with -1\n",
    "hdbscan_df_test_wo['cluster_label'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centroids_new = {}\n",
    "for old, new in cluster_mapping.items():\n",
    "    cluster_centroids_new[new] = cluster_centroids[old]\n",
    "\n",
    "hdbscan_df['old_cluster'] = hdbscan_df['cluster_label']\n",
    "hdbscan_df['cluster_label'] = hdbscan_df['cluster_label'].map(cluster_mapping)\n",
    "#replace cluster_label Nan with -1\n",
    "hdbscan_df['cluster_label'].fillna(-1, inplace=True)\n",
    "\n",
    "try:\n",
    "    hdbscan_df_test['old_cluster'] = hdbscan_df_test['cluster_label']\n",
    "    hdbscan_df_test['cluster_label'] = hdbscan_df_test['cluster_label'].map(cluster_mapping)\n",
    "    #replace cluster_label Nan with -1\n",
    "    hdbscan_df_test['cluster_label'].fillna(-1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import seaborn as sns\n",
    "sns.violinplot(data=hdbscan_df, x=\"cluster_label\", y=\"severity_score_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sns.violinplot(data=hdbscan_df_test, x=\"cluster_label\", y=\"severity_score_norm\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd09c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    hdbscan_df_test['train_test'] = 'test'\n",
    "    hdbscan_df['train_test'] = 'train'\n",
    "\n",
    "    df = pd.concat([hdbscan_df, hdbscan_df_test], ignore_index=True)\n",
    "except:\n",
    "    df = hdbscan_df\n",
    "    \n",
    "\n",
    "df.to_csv(os.path.join(filepath, f'{methods}_{run}_umap_hdbscan_severity_scores.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8cc683",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7621bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get colormap used here\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "cmap = cm.get_cmap('Set3', len(cluster_centroids_new)+1)\n",
    "\n",
    "#for cluster colors include noise point -1 not in clster_centroids_new\n",
    "cluster_colors = {-1: mcolors.to_hex(cmap(0))}\n",
    "cluster_colors.update({cluster: mcolors.to_hex(cmap(i+1)) for i, cluster in enumerate(cluster_centroids_new.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_label'] = df['cluster_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461742aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {str(k): v for k, v in cluster_colors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=df[df['cluster_label']!=-1],\n",
    "    x=\"cluster_label\",\n",
    "    y=\"severity_score_norm\",\n",
    "    # palette=cluster_colors,\n",
    "    color = '#80b1d3',\n",
    "    width=0.6,\n",
    "    showfliers=False,     # hide outliers\n",
    "    linewidth=1.5         # thicker box borders\n",
    ")\n",
    "\n",
    "\n",
    "plt.title(\"Severity Score Distribution per Cluster\", fontsize=16, pad=15)\n",
    "plt.xlabel(\"Cluster Label\", fontsize=13)\n",
    "plt.ylabel(\"Severity Score\", fontsize=13)\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec74b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {int(k): v for k, v in cluster_colors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(\n",
    "    data=df[df['cluster_label']!=-1],\n",
    "    x=\"KL-Score\",\n",
    "    y=\"severity_score_norm\",\n",
    "    hue=\"cluster_label\",\n",
    "    palette=cluster_colors,\n",
    "    estimator=\"mean\",\n",
    "    errorbar=\"sd\",   # or None if you want no error bars\n",
    "    dodge=True\n",
    ")\n",
    "\n",
    "plt.legend(\n",
    "    title=\"Cluster\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Severity Score Distribution per KL-Score\", fontsize=16, pad=15)\n",
    "plt.xlabel(\"KL-Score\", fontsize=13)\n",
    "plt.ylabel(\"Severity Score (normalized)\", fontsize=13)\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e911c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_mapping.update({-1: -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors_old = {int(k): v for k, v in cluster_colors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_colors use colors for clusters using cluster_mapping in reverse\n",
    "cluster_colors_old = {old: cluster_colors_old[new] for old, new in cluster_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bcc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn cluster_colors keys into str\n",
    "cluster_colors_old = {str(k): v for k, v in cluster_colors_old.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e3e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"old_cluster\",\n",
    "    y=\"severity_score_norm\",\n",
    "    palette=cluster_colors_old, #why is this not working?\n",
    "    width=0.6,\n",
    "    showfliers=False,     # hide outliers\n",
    "    linewidth=1.5         # thicker box borders\n",
    ")\n",
    "\n",
    "plt.title(\"Severity Score Distribution per Cluster\", fontsize=16, pad=15)\n",
    "plt.xlabel(\"Cluster Label\", fontsize=13)\n",
    "plt.ylabel(\"Severity Score\", fontsize=13)\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b836b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=df[df['cluster_label']!=-1],\n",
    "    x=\"KL-Score\",\n",
    "    y=\"severity_score_norm\",\n",
    "    color = '#ffed6f',\n",
    "    # palette=cluster_colors_old, #why is this not working?\n",
    "    width=0.6,\n",
    "    showfliers=False,     # hide outliers\n",
    "    linewidth=1.5         # thicker box borders\n",
    ")\n",
    "\n",
    "plt.title(\"Severity Score Distribution per KL-Score\", fontsize=16, pad=15)\n",
    "plt.xlabel(\"KL-Score\", fontsize=13)\n",
    "plt.ylabel(\"Severity Score\", fontsize=13)\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755414a",
   "metadata": {},
   "source": [
    "## Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a29cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"cluster_label\",\n",
    "    y=\"mean\",\n",
    "    hue = 'cluster_label',\n",
    "    palette=cluster_colors, #why is this not working?\n",
    "    width=0.6,\n",
    "    showfliers=False,     # hide outliers\n",
    "    linewidth=1.5         # thicker box borders\n",
    ")\n",
    "\n",
    "plt.title(\"Anomaly Score Distribution per Cluster\", fontsize=16, pad=15)\n",
    "plt.xlabel(\"Cluster Label\", fontsize=13)\n",
    "plt.ylabel(\"Anomaly Score\", fontsize=13)\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc02582",
   "metadata": {},
   "source": [
    "# Plot original data & SMOTE in embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hdbscan_utils import plot_hdbscan, plot_hdbscan_wcentroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f570a",
   "metadata": {},
   "source": [
    "## New Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f27d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if methods == 'comb_modalities':\n",
    "    np.save(os.path.join(filepath, f'X_umap_embeddings_wonoise.npy'), embeddings_won)\n",
    "    np.save(os.path.join(filepath, f'X_text_umap_embeddings_wonoise.npy'), embeddings_test_won)\n",
    "    np.save(os.path.join(filepath, f'X_umap_samp_embeddings_wonoise.npy'), smote_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.shape)\n",
    "print(len(hdbscan_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f71de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hdbscan_wcentroid(X = embeddings,\n",
    "            labels = hdbscan_df['cluster_label'],\n",
    "            centroids_dict=cluster_centroids_new,\n",
    "            n_clusters=len(cluster_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hdbscan_df_test))\n",
    "print(len(embeddings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hdbscan_wcentroid(X = embeddings_test,\n",
    "            labels = hdbscan_df_test['cluster_label'],\n",
    "            centroids_dict=cluster_centroids_new,\n",
    "            n_clusters=len(cluster_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_embeddings = np.concatenate([embeddings_won, embeddings_test_won], axis=0)\n",
    "print(full_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eefe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hdbscan_wcentroid(X = full_embeddings,\n",
    "            labels = pd.concat([hdbscan_df_wo['cluster_label'], hdbscan_df_test_wo['cluster_label']]),\n",
    "            centroids_dict=cluster_centroids_new,\n",
    "            n_clusters=len(hdbscan_df_wo['cluster_label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hdbscan_wcentroid(X = smote_embeddings,\n",
    "            labels = smote_df['cluster_label'],\n",
    "            centroids_dict=cluster_centroids_new,\n",
    "            n_clusters=len(cluster_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe8144",
   "metadata": {},
   "source": [
    "# Image Folder per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images per cluster\n",
    "import shutil\n",
    "\n",
    "output_path = os.path.join(DATAPATH, 'outputs', 'clusterimages', f'{methods}_{run}_umap_hdbscan_cluster_label')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "img_path = os.path.join(base_dir, 'images_knee')\n",
    "for cluster in df['cluster_label'].unique():\n",
    "    ids = df[df['cluster_label'] == cluster]['id'].tolist()\n",
    "    cluster_dir = os.path.join(output_path, f'cluster_{cluster}')\n",
    "    os.makedirs(cluster_dir, exist_ok=True)\n",
    "    for id_ in ids:\n",
    "        img_file = os.path.join(img_path, f'{id_}.png')\n",
    "        if os.path.exists(img_file):\n",
    "            dest_file = os.path.join(cluster_dir, f'{id_}.png')\n",
    "            if not os.path.exists(dest_file):\n",
    "                shutil.copy2(img_file, dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93730fb4",
   "metadata": {},
   "source": [
    "# Get Images per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_id(img_path):\n",
    "    return os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "\n",
    "def show_cluster_examples(output_path, df, max_grid=3, seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Build KL lookup\n",
    "    kl_lookup = dict(zip(df['name'], df['KL-Score']))\n",
    "\n",
    "    clusters = sorted([c for c in os.listdir(output_path) if c.startswith(\"cluster_\")])\n",
    "    img_names_d = {}\n",
    "\n",
    "    for cluster in clusters:\n",
    "        cluster_dir = os.path.join(output_path, cluster)\n",
    "\n",
    "        imgs = [\n",
    "            os.path.join(cluster_dir, f)\n",
    "            for f in os.listdir(cluster_dir)\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "\n",
    "        if len(imgs) == 0:\n",
    "            print(f\"No images found in {cluster}\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Group images by KL-score\n",
    "        # -----------------------------\n",
    "        imgs_by_kl = {}\n",
    "        for img_path in imgs:\n",
    "            img_id = get_image_id(img_path)\n",
    "            kl = kl_lookup.get(img_id, None)\n",
    "            if kl is None:\n",
    "                continue\n",
    "            imgs_by_kl.setdefault(kl, []).append(img_path)\n",
    "\n",
    "        available_kls = sorted(imgs_by_kl.keys())\n",
    "\n",
    "        if len(available_kls) == 0:\n",
    "            print(f\"No KL-labelled images in {cluster}\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Ensure at least one per KL\n",
    "        # -----------------------------\n",
    "        sample_imgs = []\n",
    "\n",
    "        for kl in available_kls:\n",
    "            sample_imgs.append(random.choice(imgs_by_kl[kl]))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Fill remaining slots (if any)\n",
    "        # -----------------------------\n",
    "        max_images = max_grid * max_grid\n",
    "        remaining = max_images - len(sample_imgs)\n",
    "\n",
    "        if remaining > 0:\n",
    "            remaining_imgs = [\n",
    "                img for img in imgs\n",
    "                if img not in sample_imgs\n",
    "            ]\n",
    "\n",
    "            if len(remaining_imgs) > 0:\n",
    "                sample_imgs.extend(\n",
    "                    random.sample(\n",
    "                        remaining_imgs,\n",
    "                        min(remaining, len(remaining_imgs))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # img_names_l.append(sample_imgs)\n",
    "        img_names_d[cluster] = imgs\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot\n",
    "        # -----------------------------\n",
    "        n_images = len(sample_imgs)\n",
    "        cols = min(max_grid, n_images)\n",
    "        rows = (n_images + cols - 1) // cols\n",
    "\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "        fig.suptitle(\n",
    "            f\"Cluster {cluster.replace('cluster_', '')}: Example Images\",\n",
    "            fontsize=18\n",
    "        )\n",
    "\n",
    "        if rows == 1 and cols == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1:\n",
    "            axes = axes\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "\n",
    "        for ax, img_path in zip(axes, sample_imgs):\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            img_id = get_image_id(img_path)\n",
    "            kl = kl_lookup.get(img_id, \"KL ?\")\n",
    "\n",
    "            ax.text(\n",
    "                0.02, 0.02,\n",
    "                f\"KL {kl}\",\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=14,\n",
    "                color=\"white\",\n",
    "                ha=\"left\",\n",
    "                va=\"bottom\",\n",
    "                bbox=dict(facecolor=\"black\", alpha=0.5, pad=2)\n",
    "            )\n",
    "\n",
    "        # Hide unused axes\n",
    "        for ax in axes[len(sample_imgs):]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return img_names_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_d = show_cluster_examples(output_path, df, max_grid=3, seed=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47f2b1",
   "metadata": {},
   "source": [
    "## Get images per cluster, grouped by KL score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a15a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_id(img_path):\n",
    "    return os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "\n",
    "def show_cluster_examples(output_path, df, max_grid=3, seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Build KL lookup\n",
    "    kl_lookup = dict(zip(df['name'], df['KL-Score']))\n",
    "    mri_cart_lookup = dict(zip(df['name'], df['mri_cart_yn']))\n",
    "    mri_osteo_lookup = dict(zip(df['name'], df['mri_osteo_yn']))\n",
    "    mri_bml_lookup = dict(zip(df['name'], df['mri_bml_yn']))\n",
    "\n",
    "    clusters = sorted([c for c in os.listdir(output_path) if c.startswith(\"cluster_\")])\n",
    "\n",
    "    for cluster in clusters:\n",
    "        cluster_dir = os.path.join(output_path, cluster)\n",
    "\n",
    "        imgs = [\n",
    "            os.path.join(cluster_dir, f)\n",
    "            for f in os.listdir(cluster_dir)\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "\n",
    "        if len(imgs) == 0:\n",
    "            print(f\"No images found in {cluster}\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Group images by KL-score\n",
    "        # -----------------------------\n",
    "        imgs_by_kl = {}\n",
    "        for img_path in imgs:\n",
    "            img_id = get_image_id(img_path)\n",
    "            kl = kl_lookup.get(img_id, None)\n",
    "            if kl is None:\n",
    "                continue\n",
    "            mri_cart = mri_cart_lookup.get(img_id, None)\n",
    "            mri_osteo = mri_osteo_lookup.get(img_id, None)\n",
    "            mri_bml = mri_bml_lookup.get(img_id, None)\n",
    "            # imgs_by_kl.setdefault(kl, []).append(img_path)\n",
    "            imgs_by_kl.setdefault(kl, []).append({\n",
    "                    \"path\": img_path,\n",
    "                    \"cart\": mri_cart,\n",
    "                    \"osteo\": mri_osteo,\n",
    "                    \"bml\": mri_bml\n",
    "                })\n",
    "\n",
    "\n",
    "        available_kls = sorted(imgs_by_kl.keys())\n",
    "\n",
    "        if len(available_kls) == 0:\n",
    "            print(f\"No KL-labelled images in {cluster}\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Prepare grid: one row per KL\n",
    "        # -----------------------------\n",
    "        n_rows = len(available_kls)\n",
    "        n_cols = max_grid\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            n_rows,\n",
    "            n_cols,\n",
    "            figsize=(4 * n_cols, 4 * n_rows),\n",
    "            squeeze=False\n",
    "        )\n",
    "\n",
    "        fig.suptitle(\n",
    "            f\"Cluster {cluster.replace('cluster_', '')} - Example Images\",\n",
    "            fontsize=18\n",
    "        )\n",
    "\n",
    "        # -----------------------------\n",
    "        # Fill grid\n",
    "        # -----------------------------\n",
    "        for row_idx, kl in enumerate(available_kls):\n",
    "            kl_imgs = imgs_by_kl[kl]\n",
    "\n",
    "            # sample up to max_grid images for this KL\n",
    "            if len(kl_imgs) > max_grid:\n",
    "                kl_imgs = random.sample(kl_imgs, max_grid)\n",
    "\n",
    "            for col_idx in range(n_cols):\n",
    "                ax = axes[row_idx, col_idx]\n",
    "\n",
    "                if col_idx < len(kl_imgs):\n",
    "                    item = kl_imgs[col_idx]\n",
    "                    img = Image.open(item['path']).convert(\"L\")\n",
    "                    ax.imshow(img, cmap=\"gray\")\n",
    "\n",
    "                    ax.text(\n",
    "                        0.02, 0.02,\n",
    "                        f\"KL {kl}\",\n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=14,\n",
    "                        color=\"white\",\n",
    "                        ha=\"left\",\n",
    "                        va=\"bottom\",\n",
    "                        bbox=dict(facecolor=\"black\", alpha=0.5, pad=2)\n",
    "                    )\n",
    "                    ax.text(\n",
    "                                0.98, 0.98,                 # top-right corner\n",
    "                                  f\"Cart: {item['cart']}\\n\"\n",
    "                                    f\"Osteo: {item['osteo']}\\n\"\n",
    "                                    f\"BML: {item['bml']}\",        # any extra info you want\n",
    "                                transform=ax.transAxes,\n",
    "                                fontsize=14,\n",
    "                                color=\"white\",\n",
    "                                ha=\"right\",                 # horizontal alignment\n",
    "                                va=\"top\",                   # vertical alignment\n",
    "                                bbox=dict(\n",
    "                                    facecolor=\"black\",\n",
    "                                    alpha=0.5,\n",
    "                                    pad=3\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "                else:\n",
    "                    ax.axis(\"off\")\n",
    "\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri = df.merge(mri, how = 'left', left_on='name', right_on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fe6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri = df_mri.dropna(subset=['mri_side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cluster_examples(output_path, df_mri,  max_grid = 3, seed = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf825c",
   "metadata": {},
   "source": [
    "## Column KL-score, row clsuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sorted([c for c in os.listdir(output_path) if c.startswith(\"cluster_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f223355",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.remove('cluster_-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bc5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_id(img_path):\n",
    "    return os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "\n",
    "def show_cluster_examples_klscores(output_path, df, seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Build KL lookup\n",
    "    kl_lookup = dict(zip(df['name'], df['KL-Score']))\n",
    "\n",
    "    clusters = sorted([c for c in os.listdir(output_path) if c.startswith(\"cluster_\")])\n",
    "    clusters.remove(\"cluster_-1\")  # Exclude noise cluster\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # First pass: collect images per (cluster, KL)\n",
    "    # -------------------------------------------------\n",
    "    cluster_kl_images = {}\n",
    "    all_kls = set()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        cluster_dir = os.path.join(output_path, cluster)\n",
    "\n",
    "        imgs = [\n",
    "            os.path.join(cluster_dir, f)\n",
    "            for f in os.listdir(cluster_dir)\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "\n",
    "        kl_map = {}\n",
    "        for img_path in imgs:\n",
    "            img_id = get_image_id(img_path)\n",
    "            kl = kl_lookup.get(img_id, None)\n",
    "            if kl is None:\n",
    "                continue\n",
    "            kl_map.setdefault(kl, []).append(img_path)\n",
    "            all_kls.add(kl)\n",
    "\n",
    "        cluster_kl_images[cluster] = kl_map\n",
    "\n",
    "    all_kls = sorted(all_kls)\n",
    "\n",
    "    if len(all_kls) == 0:\n",
    "        print(\"No KL-labelled images found.\")\n",
    "        return\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Prepare grid: rows = clusters, cols = KLs\n",
    "    # -------------------------------------------------\n",
    "    n_rows = len(clusters)\n",
    "    n_cols = len(all_kls)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows,\n",
    "        n_cols,\n",
    "        figsize=(4 * n_cols, 4 * n_rows),\n",
    "        squeeze=False\n",
    "    )\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"Cluster  KL example images\",\n",
    "        fontsize=20\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Column titles (KL scores)\n",
    "    # -------------------------------------------------\n",
    "    for col_idx, kl in enumerate(all_kls):\n",
    "        axes[0, col_idx].set_title(f\"KL {kl}\", fontsize=14)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Fill grid\n",
    "    # -------------------------------------------------\n",
    "    for row_idx, cluster in enumerate(clusters):\n",
    "        kl_map = cluster_kl_images.get(cluster, {})\n",
    "\n",
    "        # Row label (cluster)\n",
    "        axes[row_idx, 0].set_ylabel(\n",
    "            cluster.replace(\"cluster_\", \"Cluster \"),\n",
    "            fontsize=14,\n",
    "            rotation=0,\n",
    "            labelpad=60,\n",
    "            va=\"center\"\n",
    "        )\n",
    "\n",
    "        for col_idx, kl in enumerate(all_kls):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "\n",
    "            imgs_for_cell = kl_map.get(kl, [])\n",
    "\n",
    "            if len(imgs_for_cell) > 0:\n",
    "                img_path = random.choice(imgs_for_cell)\n",
    "                img = Image.open(img_path).convert(\"L\")\n",
    "                ax.imshow(img, cmap=\"gray\")\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "            else:\n",
    "                if col_idx != 0:   # keep first column axis alive\n",
    "                    ax.axis(\"off\")\n",
    "                    # ax.set_visible(False)\n",
    "                    # ax.remove()\n",
    "                else:\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7189defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cluster_examples_klscores(output_path, df[df['old_cluster']!=-1], seed=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
