{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860b930d",
   "metadata": {},
   "source": [
    "For stage ss it will be \"centre_mean\" else \"w_centre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import kruskal, combine_pvalues, spearmanr\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_fscore_support, f1_score, cohen_kappa_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52deca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant_heatmap(result, alpha = 0.05):\n",
    "    mask = result < alpha\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.heatmap(result, annot=True, fmt=\".3f\", cmap='coolwarm_r', cbar = False)\n",
    "    for i in range(result.shape[0]):\n",
    "        for j in range(result.shape[1]):\n",
    "            if not mask[i, j]:\n",
    "                ax.text(j + 0.5, i + 0.5, '', ha='center', va='center', color='blue')\n",
    "    plt.show()\n",
    "\n",
    "def get_pvalues(df):\n",
    "    pval = df.where(np.triu(np.ones(df.shape), k=1).astype(bool)).stack().values\n",
    "    _, global_p = combine_pvalues(pval, method='stouffer')\n",
    "    return pval, global_p\n",
    "\n",
    "def kruskal_wallis_analysis(df, val_column, cluster_col):\n",
    "    groups = [group[val_column].values for name, group in df.groupby(cluster_col)]\n",
    "    stat, p = kruskal(*groups)\n",
    "    print(f\"Kruskal–Wallis H-statistic: {stat:.3f}\")\n",
    "    print(f\"p-value: {p:.4f}\")\n",
    "\n",
    "    if stat > 10 and p < 0.05:\n",
    "        print(\"Post-hoc Dunn's test results:\")\n",
    "        dunns = sp.posthoc_dunn(df, val_col=val_column, group_col=cluster_col, p_adjust='bonferroni')\n",
    "        print(f\"Combined p-value (Stouffer's method): {get_pvalues(dunns)[1]:.4f}\")\n",
    "        significant_heatmap(dunns.values)\n",
    "        # display(sp.posthoc_dunn(df, val_col=val_column, group_col=cluster_col, p_adjust='bonferroni'))\n",
    "        print(\"Post-hoc Conover's test results:\")\n",
    "        conover = sp.posthoc_conover(df, val_col=val_column, group_col=cluster_col, p_adjust='holm')\n",
    "        print(f\"Combined p-value (Stouffer's method): {get_pvalues(conover)[1]:.4f}\")\n",
    "        # display(sp.posthoc_conover(df, val_col=val_column, group_col=cluster_col, p_adjust='holm'))\n",
    "        significant_heatmap(conover.values)\n",
    "\n",
    "def get_metrics(df, label = \"cluster_label\", score = \"mean\"):\n",
    "    results = {}\n",
    "    labels = df[label].unique().tolist()\n",
    "    labels.sort()\n",
    "\n",
    "    res = spearmanr(df[score].tolist(), df[label].tolist())\n",
    "    results['spearmanr'] = res[0]\n",
    "\n",
    "    for i in range(len(labels)-1):\n",
    "        df['binary_label'] = 0\n",
    "        df.loc[df[label] > labels[i], 'binary_label'] = 1\n",
    "        fpr, tpr, thresholds = roc_curve(np.array(df['binary_label']),np.array(df[score]))\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        ap_score = average_precision_score(np.array(df['binary_label']),np.array(df[score]))\n",
    "       \n",
    "        results[f'cluster_{labels[i]}'] = {'roc_auc': auc,\n",
    "                                             'average_precision': ap_score}\n",
    "        # results[f'cluster_{labels[i]}'] = {'roc_auc': auc,\n",
    "        #                                    'fpr': fpr,\n",
    "        #                                    'tpr': tpr}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c772dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = 'ss'\n",
    "#MOD_PREFIX = \"mod_2\"\n",
    "MOD_PREFIX = \"mod_smallimg\"\n",
    "NEPOCH = 400\n",
    "\n",
    "#DATAPATH = config.CHENETAL_DATAPATH\n",
    "DATAPATH = config.OUTPUT_PATH\n",
    "base_dir = config.RAW_DATA_PATH\n",
    "outputs = os.path.join(DATAPATH, 'outputs', 'dfs', STAGE)\n",
    "\n",
    "anomalyscore_metric = \"centre_mean\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d3a6f",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3961d",
   "metadata": {},
   "source": [
    "## Get Aggregated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath =  []\n",
    "for file in os.listdir(outputs):\n",
    "    if MOD_PREFIX in file and str(NEPOCH) in file:\n",
    "        filepath.append(os.path.join(outputs, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for path in filepath:\n",
    "    df = pd.read_csv(path)[['id', anomalyscore_metric]]  # only keep id + target col\n",
    "    dfs.append(df.rename(columns={anomalyscore_metric: os.path.basename(path)})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    combined = pd.merge(combined, df, on='id', how=\"inner\")  # 'inner' keeps only common IDs\n",
    "\n",
    "experiment_cols = [c for c in combined.columns if c != 'id']\n",
    "combined[\"mean\"] = combined[experiment_cols].mean(axis=1)\n",
    "combined[\"std\"] = combined[experiment_cols].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(os.path.join(outputs, f\"{MOD_PREFIX}_{STAGE}_aggregated_scores.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076a4fe",
   "metadata": {},
   "source": [
    "## Get Cluster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"2025-09-25_hdbscan\"\n",
    "# run = \"run42\"\n",
    "run = \"run74\"\n",
    "folder_date = folder.split('_')[0]\n",
    "\n",
    "filepath = os.path.join(DATAPATH, folder, \"questionnaire\", run)\n",
    "save_path = os.path.join(filepath, \"img\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "df = pd.read_csv(os.path.join(filepath, f'questionnaire_{run}_umap_hdbscan_scaled_wKL.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0991f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_col = \"cluster_label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d9034",
   "metadata": {},
   "source": [
    "# Analysis Anomaly Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a117ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['filepath'] = combined['id']\n",
    "combined['id'] = combined['id'].apply(lambda x: x.split('/')[-1].replace('.png', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16631f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = combined.merge(df, on='id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6783fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605477df",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(dfc[cluster_col].unique())\n",
    "l.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=dfc, x=cluster_col, y='mean', order=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in l:\n",
    "    plt.hist(dfc[dfc[cluster_col]==cluster]['mean'], alpha=0.5, bins=30, label=f'Cluster {cluster}')\n",
    "    plt.legend()\n",
    "    plt.title(f'Histogram of Anomaly Scores for Cluster {cluster}')\n",
    "    plt.xlabel('Anomaly Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce47740",
   "metadata": {},
   "source": [
    "## Kruskal Wallis\n",
    "\n",
    "Null HT: All clusters have the same distribution of anomaly scores.\n",
    "\n",
    "Alternative HT: At least one cluster has a different distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea13211",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [group['mean'].values for name, group in dfc.groupby(cluster_col)]\n",
    "stat, p = kruskal(*groups)\n",
    "print(f\"Kruskal–Wallis H-statistic: {stat:.3f}\")\n",
    "print(f\"p-value: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc3437",
   "metadata": {},
   "source": [
    "H large -> at least one group differs, if p-value < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562fb26",
   "metadata": {},
   "source": [
    "## Post-hoc Pairwise test\n",
    "\n",
    "Pairwise comparison, to see if only one group significantly differs or multiple groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a43f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_wallis_analysis(dfc, val_column = 'mean', cluster_col = cluster_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d4454",
   "metadata": {},
   "source": [
    "Shows not significant difference here between 0, 1, and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1909eb",
   "metadata": {},
   "source": [
    "# Comparison to MRI Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c55e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri = pd.read_csv(os.path.join(base_dir, '2025-09-25_mrismall.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ed877",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc2 = dfc.merge(mri, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55642b39",
   "metadata": {},
   "source": [
    "## MRI Cartilage Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_wallis_analysis(dfc2, 'mri_cart_yn', cluster_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa350f8",
   "metadata": {},
   "source": [
    "## MRI Osteophytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e57d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_wallis_analysis(dfc2, 'mri_osteo_yn', cluster_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec116f81",
   "metadata": {},
   "source": [
    "## MRI BML (lesions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_wallis_analysis(dfc2, 'mri_bml_yn', cluster_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7578d",
   "metadata": {},
   "source": [
    "# ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_metrics(dfc2, label = cluster_col, score = 'mean')\n",
    "for i in range(1,len(results.items())):\n",
    "    print(f\"Metrics for cluster_{i-1}:\")\n",
    "    print(results[f'cluster_{i-1}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee08d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average ROC_AUC across clusters: {np.mean([results[f'cluster_{i}']['roc_auc'] for i in range(len(results)-1)]):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
